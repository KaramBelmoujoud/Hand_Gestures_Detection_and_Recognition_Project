{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rodWEAufWN2y"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N0b9wzQ0WN24"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import uuid\n",
        "import os\n",
        "import copy\n",
        "import itertools\n",
        "from collections import deque, Counter\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NsuViGsDh-oH"
      },
      "source": [
        "# Read labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FDYT9xlThahn"
      },
      "outputs": [],
      "source": [
        "actions = ['stop','goLeft', 'goRight', 'modeDiaPo','modeNormal']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aBtbMyJ6WN3p"
      },
      "source": [
        "# **Build and Train The Gestures Model**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nK6bWXlZDNVL"
      },
      "source": [
        "**input shape**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VUm3kZJC8ej"
      },
      "outputs": [],
      "source": [
        "TIME_STEPS = 16\n",
        "DIMENSION = 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hkCGElqkDb5N"
      },
      "source": [
        "**Load DataSet and  Features & lables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QpSZjKVPD15y"
      },
      "outputs": [],
      "source": [
        "dataset = 'Gestures_Presentation_Controle_DataSet/Gesture_Keypoints.csv'\n",
        "model_save_path = 'Model/Gestures_classifier_MetaData.h5'\n",
        "Logs = 'C:/oussamaboussaid/Hand_Gestures_Detection_and_Recognition_Project/Logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I8KrPaiqDbdm"
      },
      "outputs": [],
      "source": [
        "X_features  = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))\n",
        "Y_lables  = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
        "\n",
        "# split features ana lables into train and test\n",
        "RANDOM_SEED = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, Y_lables, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(576, 32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cl2NdZWFhvz"
      },
      "source": [
        "**Define a Callback to use for EarlyStopping & TensorBoard**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DXEZfStzFfEi"
      },
      "outputs": [],
      "source": [
        "\n",
        "log_dir = os.path.join('C:/oussamaboussaid/Hand_Gestures_Detection_and_Recognition_Project/Logs')\n",
        "TB_callback = TensorBoard(log_dir=log_dir)\n",
        "\n",
        "# callback for earlyStopping\n",
        "Earlystopping_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**launch TensorBoardSession**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorboard -- logdir={log_folder}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VHrhIdYGEeX0"
      },
      "source": [
        "**Build The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Uq12oEAJE37o"
      },
      "outputs": [],
      "source": [
        "# Modl Param\n",
        "use_lstm = False\n",
        "NUM_CLASSES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BKcTUfUBD9Gh"
      },
      "outputs": [],
      "source": [
        "if use_lstm:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "else:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c1h-_dbHGYn3"
      },
      "outputs": [],
      "source": [
        "model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vPh6RduzGglX"
      },
      "source": [
        "**Train The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z8zinCJ8Gelv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 46ms/step - loss: 1.6037 - accuracy: 0.7552 - val_loss: 1.5860 - val_accuracy: 0.8135\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5824 - accuracy: 0.8056 - val_loss: 1.5662 - val_accuracy: 0.8549\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5666 - accuracy: 0.8177 - val_loss: 1.5470 - val_accuracy: 0.8912\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5484 - accuracy: 0.8212 - val_loss: 1.5281 - val_accuracy: 0.9171\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5367 - accuracy: 0.8229 - val_loss: 1.5098 - val_accuracy: 0.9171\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5159 - accuracy: 0.8438 - val_loss: 1.4913 - val_accuracy: 0.9326\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5054 - accuracy: 0.8299 - val_loss: 1.4730 - val_accuracy: 0.9378\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4707 - accuracy: 0.8559 - val_loss: 1.4545 - val_accuracy: 0.9430\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4583 - accuracy: 0.8628 - val_loss: 1.4357 - val_accuracy: 0.9430\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4379 - accuracy: 0.8819 - val_loss: 1.4161 - val_accuracy: 0.9430\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4169 - accuracy: 0.8872 - val_loss: 1.3959 - val_accuracy: 0.9430\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4021 - accuracy: 0.8837 - val_loss: 1.3749 - val_accuracy: 0.9430\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3758 - accuracy: 0.8837 - val_loss: 1.3525 - val_accuracy: 0.9430\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3502 - accuracy: 0.8785 - val_loss: 1.3292 - val_accuracy: 0.9430\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3292 - accuracy: 0.8802 - val_loss: 1.3049 - val_accuracy: 0.9430\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3211 - accuracy: 0.8750 - val_loss: 1.2797 - val_accuracy: 0.9430\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2973 - accuracy: 0.8767 - val_loss: 1.2536 - val_accuracy: 0.9430\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2662 - accuracy: 0.8854 - val_loss: 1.2265 - val_accuracy: 0.9430\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2492 - accuracy: 0.8785 - val_loss: 1.1985 - val_accuracy: 0.9430\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2142 - accuracy: 0.8767 - val_loss: 1.1691 - val_accuracy: 0.9378\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1897 - accuracy: 0.8767 - val_loss: 1.1384 - val_accuracy: 0.9326\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1599 - accuracy: 0.8802 - val_loss: 1.1060 - val_accuracy: 0.9326\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1219 - accuracy: 0.8785 - val_loss: 1.0721 - val_accuracy: 0.9223\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0930 - accuracy: 0.8802 - val_loss: 1.0367 - val_accuracy: 0.9067\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0506 - accuracy: 0.8767 - val_loss: 1.0004 - val_accuracy: 0.9016\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0069 - accuracy: 0.8837 - val_loss: 0.9631 - val_accuracy: 0.8964\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.9877 - accuracy: 0.8663 - val_loss: 0.9236 - val_accuracy: 0.8912\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9522 - accuracy: 0.8663 - val_loss: 0.8834 - val_accuracy: 0.8912\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9220 - accuracy: 0.8681 - val_loss: 0.8422 - val_accuracy: 0.8912\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8692 - accuracy: 0.8750 - val_loss: 0.8011 - val_accuracy: 0.8912\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8653 - accuracy: 0.8628 - val_loss: 0.7595 - val_accuracy: 0.8912\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8136 - accuracy: 0.8611 - val_loss: 0.7179 - val_accuracy: 0.8912\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7619 - accuracy: 0.8681 - val_loss: 0.6771 - val_accuracy: 0.8912\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7230 - accuracy: 0.8681 - val_loss: 0.6376 - val_accuracy: 0.8912\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7004 - accuracy: 0.8628 - val_loss: 0.5991 - val_accuracy: 0.8912\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6518 - accuracy: 0.8646 - val_loss: 0.5622 - val_accuracy: 0.8912\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6321 - accuracy: 0.8646 - val_loss: 0.5271 - val_accuracy: 0.8912\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.8750 - val_loss: 0.4943 - val_accuracy: 0.8912\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5805 - accuracy: 0.8628 - val_loss: 0.4638 - val_accuracy: 0.8912\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5424 - accuracy: 0.8576 - val_loss: 0.4356 - val_accuracy: 0.8912\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5439 - accuracy: 0.8594 - val_loss: 0.4099 - val_accuracy: 0.8912\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5158 - accuracy: 0.8507 - val_loss: 0.3871 - val_accuracy: 0.8912\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4926 - accuracy: 0.8681 - val_loss: 0.3655 - val_accuracy: 0.8912\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4723 - accuracy: 0.8628 - val_loss: 0.3453 - val_accuracy: 0.8912\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4497 - accuracy: 0.8681 - val_loss: 0.3265 - val_accuracy: 0.8912\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4418 - accuracy: 0.8628 - val_loss: 0.3093 - val_accuracy: 0.8912\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8767 - val_loss: 0.2932 - val_accuracy: 0.8912\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8733 - val_loss: 0.2781 - val_accuracy: 0.8912\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3928 - accuracy: 0.8767 - val_loss: 0.2644 - val_accuracy: 0.8964\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3812 - accuracy: 0.8767 - val_loss: 0.2513 - val_accuracy: 0.9067\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3869 - accuracy: 0.8733 - val_loss: 0.2390 - val_accuracy: 0.9067\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3635 - accuracy: 0.8854 - val_loss: 0.2275 - val_accuracy: 0.9326\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3585 - accuracy: 0.8872 - val_loss: 0.2171 - val_accuracy: 0.9378\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3547 - accuracy: 0.8906 - val_loss: 0.2076 - val_accuracy: 0.9482\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3130 - accuracy: 0.8958 - val_loss: 0.1986 - val_accuracy: 0.9585\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3404 - accuracy: 0.9028 - val_loss: 0.1901 - val_accuracy: 0.9689\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.9115 - val_loss: 0.1822 - val_accuracy: 0.9741\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3096 - accuracy: 0.9045 - val_loss: 0.1746 - val_accuracy: 0.9793\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3175 - accuracy: 0.9080 - val_loss: 0.1683 - val_accuracy: 0.9793\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2592 - accuracy: 0.9288 - val_loss: 0.1620 - val_accuracy: 0.9793\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2740 - accuracy: 0.9236 - val_loss: 0.1555 - val_accuracy: 0.9896\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2629 - accuracy: 0.9323 - val_loss: 0.1488 - val_accuracy: 0.9896\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2762 - accuracy: 0.9236 - val_loss: 0.1421 - val_accuracy: 0.9896\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2640 - accuracy: 0.9219 - val_loss: 0.1363 - val_accuracy: 0.9948\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2340 - accuracy: 0.9479 - val_loss: 0.1301 - val_accuracy: 0.9948\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.9306 - val_loss: 0.1240 - val_accuracy: 0.9948\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2268 - accuracy: 0.9444 - val_loss: 0.1181 - val_accuracy: 0.9948\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.9236 - val_loss: 0.1135 - val_accuracy: 0.9948\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2029 - accuracy: 0.9549 - val_loss: 0.1091 - val_accuracy: 0.9948\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2184 - accuracy: 0.9462 - val_loss: 0.1050 - val_accuracy: 0.9948\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.2069 - accuracy: 0.9427 - val_loss: 0.1008 - val_accuracy: 0.9948\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2221 - accuracy: 0.9444 - val_loss: 0.0972 - val_accuracy: 0.9948\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9497 - val_loss: 0.0934 - val_accuracy: 0.9948\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9601 - val_loss: 0.0895 - val_accuracy: 0.9948\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9497 - val_loss: 0.0856 - val_accuracy: 0.9948\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1869 - accuracy: 0.9531 - val_loss: 0.0818 - val_accuracy: 0.9948\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1576 - accuracy: 0.9670 - val_loss: 0.0783 - val_accuracy: 0.9948\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1904 - accuracy: 0.9462 - val_loss: 0.0753 - val_accuracy: 0.9948\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1643 - accuracy: 0.9653 - val_loss: 0.0725 - val_accuracy: 0.9948\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1751 - accuracy: 0.9583 - val_loss: 0.0697 - val_accuracy: 0.9948\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1501 - accuracy: 0.9618 - val_loss: 0.0670 - val_accuracy: 0.9948\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9583 - val_loss: 0.0643 - val_accuracy: 0.9948\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1697 - accuracy: 0.9531 - val_loss: 0.0621 - val_accuracy: 0.9948\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.9549 - val_loss: 0.0601 - val_accuracy: 0.9948\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1807 - accuracy: 0.9549 - val_loss: 0.0587 - val_accuracy: 0.9948\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1696 - accuracy: 0.9479 - val_loss: 0.0571 - val_accuracy: 0.9948\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1657 - accuracy: 0.9531 - val_loss: 0.0556 - val_accuracy: 0.9948\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1371 - accuracy: 0.9688 - val_loss: 0.0539 - val_accuracy: 0.9948\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1516 - accuracy: 0.9705 - val_loss: 0.0520 - val_accuracy: 0.9948\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9740 - val_loss: 0.0501 - val_accuracy: 0.9948\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9688 - val_loss: 0.0484 - val_accuracy: 0.9948\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1292 - accuracy: 0.9688 - val_loss: 0.0467 - val_accuracy: 0.9948\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.9635 - val_loss: 0.0452 - val_accuracy: 0.9948\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9635 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.9722 - val_loss: 0.0434 - val_accuracy: 0.9948\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1521 - accuracy: 0.9618 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.9653 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1403 - accuracy: 0.9670 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1152 - accuracy: 0.9792 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1064 - accuracy: 0.9844 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9566 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1237 - accuracy: 0.9774 - val_loss: 0.0362 - val_accuracy: 0.9948\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1506 - accuracy: 0.9549 - val_loss: 0.0352 - val_accuracy: 0.9948\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1383 - accuracy: 0.9688 - val_loss: 0.0344 - val_accuracy: 0.9948\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1048 - accuracy: 0.9740 - val_loss: 0.0339 - val_accuracy: 0.9948\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1160 - accuracy: 0.9722 - val_loss: 0.0330 - val_accuracy: 0.9948\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1065 - accuracy: 0.9774 - val_loss: 0.0318 - val_accuracy: 0.9948\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1129 - accuracy: 0.9740 - val_loss: 0.0306 - val_accuracy: 0.9948\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1089 - accuracy: 0.9774 - val_loss: 0.0296 - val_accuracy: 0.9948\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9740 - val_loss: 0.0290 - val_accuracy: 0.9948\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1047 - accuracy: 0.9705 - val_loss: 0.0284 - val_accuracy: 0.9948\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1046 - accuracy: 0.9792 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1010 - accuracy: 0.9774 - val_loss: 0.0274 - val_accuracy: 0.9948\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9809 - val_loss: 0.0268 - val_accuracy: 0.9948\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9705 - val_loss: 0.0263 - val_accuracy: 0.9948\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1037 - accuracy: 0.9740 - val_loss: 0.0259 - val_accuracy: 0.9948\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9809 - val_loss: 0.0255 - val_accuracy: 0.9948\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0770 - accuracy: 0.9861 - val_loss: 0.0250 - val_accuracy: 0.9948\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0982 - accuracy: 0.9722 - val_loss: 0.0245 - val_accuracy: 0.9948\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 0.0242 - val_accuracy: 0.9948\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9792 - val_loss: 0.0239 - val_accuracy: 0.9948\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0906 - accuracy: 0.9809 - val_loss: 0.0237 - val_accuracy: 0.9948\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9826 - val_loss: 0.0235 - val_accuracy: 0.9948\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.9774 - val_loss: 0.0234 - val_accuracy: 0.9948\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9809 - val_loss: 0.0231 - val_accuracy: 0.9948\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0994 - accuracy: 0.9757 - val_loss: 0.0227 - val_accuracy: 0.9948\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9740 - val_loss: 0.0221 - val_accuracy: 0.9948\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1005 - accuracy: 0.9757 - val_loss: 0.0216 - val_accuracy: 0.9948\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9809 - val_loss: 0.0211 - val_accuracy: 0.9948\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9757 - val_loss: 0.0208 - val_accuracy: 0.9948\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.9826 - val_loss: 0.0206 - val_accuracy: 0.9948\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.9809 - val_loss: 0.0203 - val_accuracy: 0.9948\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0913 - accuracy: 0.9740 - val_loss: 0.0201 - val_accuracy: 0.9948\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0890 - accuracy: 0.9774 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.9757 - val_loss: 0.0198 - val_accuracy: 0.9948\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9844 - val_loss: 0.0197 - val_accuracy: 0.9948\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9878 - val_loss: 0.0193 - val_accuracy: 0.9948\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9861 - val_loss: 0.0190 - val_accuracy: 0.9948\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 0.9740 - val_loss: 0.0187 - val_accuracy: 0.9948\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 0.0183 - val_accuracy: 0.9948\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0178 - val_accuracy: 0.9948\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 0.0171 - val_accuracy: 0.9948\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9844 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9896 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9792 - val_loss: 0.0165 - val_accuracy: 0.9948\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9878 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1039 - accuracy: 0.9705 - val_loss: 0.0161 - val_accuracy: 0.9948\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0753 - accuracy: 0.9809 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0661 - accuracy: 0.9844 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0604 - accuracy: 0.9896 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0839 - accuracy: 0.9774 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9774 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9896 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9774 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9826 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9844 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 0.9809 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 0.9896 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.9861 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0719 - accuracy: 0.9844 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9948 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9774 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9774 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0672 - accuracy: 0.9861 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0865 - accuracy: 0.9757 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0775 - accuracy: 0.9844 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0807 - accuracy: 0.9809 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0648 - accuracy: 0.9826 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9896 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9948 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0699 - accuracy: 0.9878 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9878 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9826 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9844 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9896 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0523 - accuracy: 0.9913 - val_loss: 0.0117 - val_accuracy: 0.9948\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0114 - val_accuracy: 0.9948\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.0112 - val_accuracy: 0.9948\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0743 - accuracy: 0.9809 - val_loss: 0.0110 - val_accuracy: 0.9948\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9878 - val_loss: 0.0107 - val_accuracy: 0.9948\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.0106 - val_accuracy: 0.9948\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.0105 - val_accuracy: 0.9948\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0567 - accuracy: 0.9809 - val_loss: 0.0103 - val_accuracy: 0.9948\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9913 - val_loss: 0.0101 - val_accuracy: 0.9948\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0562 - accuracy: 0.9844 - val_loss: 0.0100 - val_accuracy: 0.9948\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0494 - accuracy: 0.9878 - val_loss: 0.0099 - val_accuracy: 0.9948\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0671 - accuracy: 0.9861 - val_loss: 0.0098 - val_accuracy: 0.9948\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.9809 - val_loss: 0.0098 - val_accuracy: 0.9948\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0639 - accuracy: 0.9826 - val_loss: 0.0098 - val_accuracy: 0.9948\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9861 - val_loss: 0.0098 - val_accuracy: 0.9948\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0501 - accuracy: 0.9896 - val_loss: 0.0097 - val_accuracy: 0.9948\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9931 - val_loss: 0.0097 - val_accuracy: 0.9948\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9896 - val_loss: 0.0097 - val_accuracy: 0.9948\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 0.9913 - val_loss: 0.0096 - val_accuracy: 0.9948\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0714 - accuracy: 0.9809 - val_loss: 0.0094 - val_accuracy: 0.9948\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9878 - val_loss: 0.0093 - val_accuracy: 0.9948\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9861 - val_loss: 0.0093 - val_accuracy: 0.9948\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9931 - val_loss: 0.0094 - val_accuracy: 0.9948\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.0096 - val_accuracy: 0.9948\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0713 - accuracy: 0.9792 - val_loss: 0.0096 - val_accuracy: 0.9948\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9931 - val_loss: 0.0096 - val_accuracy: 0.9948\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0617 - accuracy: 0.9878 - val_loss: 0.0093 - val_accuracy: 0.9948\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 0.0091 - val_accuracy: 0.9948\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0500 - accuracy: 0.9913 - val_loss: 0.0088 - val_accuracy: 0.9948\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.0087 - val_accuracy: 0.9948\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9896 - val_loss: 0.0085 - val_accuracy: 0.9948\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.0083 - val_accuracy: 0.9948\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.9913 - val_loss: 0.0083 - val_accuracy: 0.9948\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9896 - val_loss: 0.0083 - val_accuracy: 0.9948\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9896 - val_loss: 0.0084 - val_accuracy: 0.9948\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9896 - val_loss: 0.0083 - val_accuracy: 0.9948\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9931 - val_loss: 0.0082 - val_accuracy: 0.9948\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9913 - val_loss: 0.0081 - val_accuracy: 0.9948\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9948 - val_loss: 0.0081 - val_accuracy: 0.9948\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.0080 - val_accuracy: 0.9948\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9878 - val_loss: 0.0078 - val_accuracy: 0.9948\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9931 - val_loss: 0.0076 - val_accuracy: 0.9948\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.0075 - val_accuracy: 0.9948\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.0074 - val_accuracy: 0.9948\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9896 - val_loss: 0.0073 - val_accuracy: 0.9948\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9878 - val_loss: 0.0072 - val_accuracy: 0.9948\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9948 - val_loss: 0.0072 - val_accuracy: 0.9948\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0072 - val_accuracy: 0.9948\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9913 - val_loss: 0.0071 - val_accuracy: 0.9948\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9896 - val_loss: 0.0069 - val_accuracy: 0.9948\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 0.9861 - val_loss: 0.0068 - val_accuracy: 0.9948\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9931 - val_loss: 0.0068 - val_accuracy: 0.9948\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.0068 - val_accuracy: 0.9948\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.0066 - val_accuracy: 0.9948\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9792 - val_loss: 0.0066 - val_accuracy: 0.9948\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 0.0065 - val_accuracy: 0.9948\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9931 - val_loss: 0.0065 - val_accuracy: 0.9948\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0531 - accuracy: 0.9844 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9931 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9931 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9878 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9913 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0424 - accuracy: 0.9896 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0554 - accuracy: 0.9826 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9861 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9913 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9861 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9965 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9931 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0547 - accuracy: 0.9913 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9965 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9844 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0506 - accuracy: 0.9878 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9948 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9861 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0505 - accuracy: 0.9861 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9931 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0518 - accuracy: 0.9878 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9931 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9931 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9878 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9948 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9965 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9878 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9948 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9931 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0459 - accuracy: 0.9913 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9896 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9965 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9913 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9913 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.9931 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9931 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.9844 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0471 - accuracy: 0.9878 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9896 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9913 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9948 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9948 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9965 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9896 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9965 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9878 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9913 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9931 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9983 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9931 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9948 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9948 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9948 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9948 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9931 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9948 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 0.9965 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9931 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9983 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9948 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0343 - accuracy: 0.9931 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9913 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.9965 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9878 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9965 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9948 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9948 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9878 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 0.9965 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 396: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b1a175e4a0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit( X_train, y_train, epochs=1000, batch_size=128, validation_data=(X_test, y_test), callbacks=[TB_callback, Earlystopping_callback] )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-MYEi2rCHM8W"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_SdpF4ABHMaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                792       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                250       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,097\n",
            "Trainable params: 1,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "80ainbBnHaUF"
      },
      "source": [
        "**Save Weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TohRVMTjHRRN"
      },
      "outputs": [],
      "source": [
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EqgxK0QnH-1F"
      },
      "source": [
        "**Test the model ( Make Predictions )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dVKeVOYEHt29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "[5.0478241e-23 1.5258454e-33 1.0000000e+00 2.9786346e-15 7.6859900e-13]\n",
            "2\n",
            "goRight\n"
          ]
        }
      ],
      "source": [
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))\n",
        "print(actions[np.argmax(np.squeeze(predict_result))])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ST-k7UC4HtIu"
      },
      "source": [
        "**Evaluate The Model**\n",
        "\n",
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\python310\\lib\\site-packages (from seaborn) (1.23.2)\n",
            "Requirement already satisfied: pandas>=0.25 in c:\\python310\\lib\\site-packages (from seaborn) (1.4.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\python310\\lib\\site-packages (from seaborn) (3.5.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.37.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.12.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BJlhMcP9IrH_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 842us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       144\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       1.00      1.00      1.00        17\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00       193\n",
            "   macro avg       1.00      1.00      1.00       193\n",
            "weighted avg       1.00      1.00      1.00       193\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YOjMMGaQMTJT"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cIvusWueOUeG"
      },
      "outputs": [],
      "source": [
        "tflite_save_path = 'Model/Gestures_classifier_MetaData.tflite'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6_VdeUznPAQH"
      },
      "source": [
        "**Transform model (quantization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2SFZL0OIO5XO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Kibbou\\AppData\\Local\\Temp\\tmppx0bbyvx\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6476"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m0NFsx5IPLNu"
      },
      "source": [
        "**Inference test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vlJdomaNPCdl"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ixfMtwVlPNpO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 32]), 'shape_signature': array([-1, 32]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "# get input/output tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.        ,  0.        ,  0.        , -0.00208333,  0.0484375 ,\n",
              "       -0.00416667, -0.3640625 , -0.31041667,  0.28125   ,  0.01041667,\n",
              "        0.3359375 ,  0.00833333,  0.3921875 ,  0.00625   ,  0.4296875 ,\n",
              "        0.0125    ,  0.459375  ,  0.01875   ,  0.509375  ,  0.02916667,\n",
              "        0.525     ,  0.03125   ,  0.5359375 ,  0.03125   ,  0.5359375 ,\n",
              "        0.02916667,  0.5421875 ,  0.03125   ,  0.546875  ,  0.03333334,\n",
              "        0.5515625 ,  0.03541667], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mns-mOWFPUzg"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4MaRZsDCPYQu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KOwMkRnRPmAU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5.0478241e-23 1.5258455e-33 1.0000000e+00 2.9786343e-15 7.6860187e-13]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Build and Train The Sign Model**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**input shape**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "hand = 21\n",
        "DIMENSION = 2\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_sign = 'Gestures_Presentation_Controle_DataSet/Sign_KeyPoints.csv'\n",
        "model_save_path_sign = 'Model/Sign_classifier_MetaData.h5'\n",
        "Logs_sign = 'C:/oussamaboussaid/Hand_Gestures_Detection_and_Recognition_Project/Logs_sign'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_features_sign = np.loadtxt(dataset_sign, delimiter=',', dtype='float32', usecols=list(range(1, (hand * DIMENSION) + 1)))\n",
        "\n",
        "y_lables_sign = np.loadtxt(dataset_sign, delimiter=',', dtype='int32', usecols=(0))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_sign, y_lables_sign, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "log_dir_sign = os.path.join('C:/oussamaboussaid/Hand_Gestures_Detection_and_Recognition_Project/Logs_sign')\n",
        "TB_callback_sign = TensorBoard(log_dir=log_dir_sign)\n",
        "\n",
        "# callback for earlyStopping\n",
        "Earlystopping_callback_sign = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorboard -- logdir={log_folder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modl Param\n",
        "NUM_CLASSES_sign = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES_sign, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_2 (Dropout)         (None, 42)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,103\n",
            "Trainable params: 1,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 1s 17ms/step - loss: 1.0545 - accuracy: 0.3824 - val_loss: 1.0163 - val_accuracy: 0.3701\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1.0296 - accuracy: 0.4485 - val_loss: 0.9978 - val_accuracy: 0.5327\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.4729 - val_loss: 0.9704 - val_accuracy: 0.5477\n",
            "Epoch 4/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9788 - accuracy: 0.5384 - val_loss: 0.9267 - val_accuracy: 0.6355\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9484 - accuracy: 0.5727 - val_loss: 0.8636 - val_accuracy: 0.8206\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.9156 - accuracy: 0.6132 - val_loss: 0.8011 - val_accuracy: 0.8860\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8869 - accuracy: 0.6170 - val_loss: 0.7480 - val_accuracy: 0.8860\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8275 - accuracy: 0.6706 - val_loss: 0.6860 - val_accuracy: 0.9103\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7917 - accuracy: 0.7012 - val_loss: 0.6212 - val_accuracy: 0.9140\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.7162 - val_loss: 0.5555 - val_accuracy: 0.9140\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7119 - accuracy: 0.7424 - val_loss: 0.4910 - val_accuracy: 0.9140\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.7536 - val_loss: 0.4478 - val_accuracy: 0.9383\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.8004 - val_loss: 0.4002 - val_accuracy: 0.9477\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.8010 - val_loss: 0.3571 - val_accuracy: 0.9477\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.8129 - val_loss: 0.3148 - val_accuracy: 0.9477\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.8197 - val_loss: 0.2873 - val_accuracy: 0.9458\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.8291 - val_loss: 0.2578 - val_accuracy: 0.9477\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.8422 - val_loss: 0.2359 - val_accuracy: 0.9533\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.8328 - val_loss: 0.2158 - val_accuracy: 0.9551\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8609 - val_loss: 0.1948 - val_accuracy: 0.9570\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8590 - val_loss: 0.1703 - val_accuracy: 0.9850\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8596 - val_loss: 0.1558 - val_accuracy: 0.9832\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8677 - val_loss: 0.1364 - val_accuracy: 0.9907\n",
            "Epoch 24/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8621 - val_loss: 0.1336 - val_accuracy: 0.9850\n",
            "Epoch 25/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8815 - val_loss: 0.1218 - val_accuracy: 0.9907\n",
            "Epoch 26/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8796 - val_loss: 0.1132 - val_accuracy: 0.9907\n",
            "Epoch 27/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8852 - val_loss: 0.1062 - val_accuracy: 0.9907\n",
            "Epoch 28/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8846 - val_loss: 0.1029 - val_accuracy: 0.9925\n",
            "Epoch 29/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.9064 - val_loss: 0.1001 - val_accuracy: 0.9925\n",
            "Epoch 30/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8915 - val_loss: 0.0934 - val_accuracy: 0.9907\n",
            "Epoch 31/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8927 - val_loss: 0.0885 - val_accuracy: 0.9925\n",
            "Epoch 32/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8902 - val_loss: 0.0887 - val_accuracy: 0.9925\n",
            "Epoch 33/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.9033 - val_loss: 0.0834 - val_accuracy: 0.9925\n",
            "Epoch 34/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.9008 - val_loss: 0.0774 - val_accuracy: 0.9925\n",
            "Epoch 35/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.9089 - val_loss: 0.0739 - val_accuracy: 0.9925\n",
            "Epoch 36/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9145 - val_loss: 0.0686 - val_accuracy: 0.9907\n",
            "Epoch 37/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9027 - val_loss: 0.0668 - val_accuracy: 0.9925\n",
            "Epoch 38/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8877 - val_loss: 0.0675 - val_accuracy: 0.9925\n",
            "Epoch 39/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9133 - val_loss: 0.0665 - val_accuracy: 0.9925\n",
            "Epoch 40/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9127 - val_loss: 0.0628 - val_accuracy: 0.9925\n",
            "Epoch 41/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9039 - val_loss: 0.0604 - val_accuracy: 0.9925\n",
            "Epoch 42/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.9114 - val_loss: 0.0604 - val_accuracy: 0.9944\n",
            "Epoch 43/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.9158 - val_loss: 0.0591 - val_accuracy: 0.9907\n",
            "Epoch 44/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.9102 - val_loss: 0.0557 - val_accuracy: 0.9944\n",
            "Epoch 45/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.9114 - val_loss: 0.0553 - val_accuracy: 0.9944\n",
            "Epoch 46/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9095 - val_loss: 0.0564 - val_accuracy: 0.9925\n",
            "Epoch 47/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9145 - val_loss: 0.0575 - val_accuracy: 0.9944\n",
            "Epoch 48/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9170 - val_loss: 0.0566 - val_accuracy: 0.9944\n",
            "Epoch 49/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9239 - val_loss: 0.0534 - val_accuracy: 0.9944\n",
            "Epoch 50/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.9158 - val_loss: 0.0546 - val_accuracy: 0.9925\n",
            "Epoch 51/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9345 - val_loss: 0.0523 - val_accuracy: 0.9925\n",
            "Epoch 52/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9376 - val_loss: 0.0507 - val_accuracy: 0.9925\n",
            "Epoch 53/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9351 - val_loss: 0.0467 - val_accuracy: 0.9944\n",
            "Epoch 54/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9333 - val_loss: 0.0453 - val_accuracy: 0.9944\n",
            "Epoch 55/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9295 - val_loss: 0.0445 - val_accuracy: 0.9944\n",
            "Epoch 56/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9239 - val_loss: 0.0442 - val_accuracy: 0.9944\n",
            "Epoch 57/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9333 - val_loss: 0.0446 - val_accuracy: 0.9944\n",
            "Epoch 58/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9414 - val_loss: 0.0458 - val_accuracy: 0.9944\n",
            "Epoch 59/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9239 - val_loss: 0.0445 - val_accuracy: 0.9944\n",
            "Epoch 60/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9301 - val_loss: 0.0471 - val_accuracy: 0.9925\n",
            "Epoch 61/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9382 - val_loss: 0.0466 - val_accuracy: 0.9925\n",
            "Epoch 62/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9326 - val_loss: 0.0459 - val_accuracy: 0.9925\n",
            "Epoch 63/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9264 - val_loss: 0.0462 - val_accuracy: 0.9925\n",
            "Epoch 64/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2189 - accuracy: 0.9357 - val_loss: 0.0437 - val_accuracy: 0.9944\n",
            "Epoch 65/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9432 - val_loss: 0.0444 - val_accuracy: 0.9925\n",
            "Epoch 66/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9370 - val_loss: 0.0438 - val_accuracy: 0.9925\n",
            "Epoch 67/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2092 - accuracy: 0.9351 - val_loss: 0.0430 - val_accuracy: 0.9925\n",
            "Epoch 68/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9482 - val_loss: 0.0410 - val_accuracy: 0.9925\n",
            "Epoch 69/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9314 - val_loss: 0.0379 - val_accuracy: 0.9944\n",
            "Epoch 70/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9395 - val_loss: 0.0384 - val_accuracy: 0.9944\n",
            "Epoch 71/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9432 - val_loss: 0.0399 - val_accuracy: 0.9944\n",
            "Epoch 72/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9326 - val_loss: 0.0409 - val_accuracy: 0.9944\n",
            "Epoch 73/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9457 - val_loss: 0.0413 - val_accuracy: 0.9925\n",
            "Epoch 74/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9339 - val_loss: 0.0414 - val_accuracy: 0.9925\n",
            "Epoch 75/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.9401 - val_loss: 0.0422 - val_accuracy: 0.9925\n",
            "Epoch 76/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9389 - val_loss: 0.0414 - val_accuracy: 0.9925\n",
            "Epoch 77/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9432 - val_loss: 0.0391 - val_accuracy: 0.9944\n",
            "Epoch 78/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9445 - val_loss: 0.0389 - val_accuracy: 0.9944\n",
            "Epoch 79/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9420 - val_loss: 0.0380 - val_accuracy: 0.9944\n",
            "Epoch 80/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1529 - accuracy: 0.9538 - val_loss: 0.0383 - val_accuracy: 0.9944\n",
            "Epoch 81/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9482 - val_loss: 0.0370 - val_accuracy: 0.9925\n",
            "Epoch 82/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9426 - val_loss: 0.0350 - val_accuracy: 0.9944\n",
            "Epoch 83/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9470 - val_loss: 0.0348 - val_accuracy: 0.9944\n",
            "Epoch 84/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9439 - val_loss: 0.0355 - val_accuracy: 0.9925\n",
            "Epoch 85/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9439 - val_loss: 0.0363 - val_accuracy: 0.9925\n",
            "Epoch 86/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9464 - val_loss: 0.0373 - val_accuracy: 0.9944\n",
            "Epoch 87/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9557 - val_loss: 0.0368 - val_accuracy: 0.9944\n",
            "Epoch 88/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9451 - val_loss: 0.0344 - val_accuracy: 0.9944\n",
            "Epoch 89/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1607 - accuracy: 0.9457 - val_loss: 0.0349 - val_accuracy: 0.9944\n",
            "Epoch 90/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9482 - val_loss: 0.0340 - val_accuracy: 0.9944\n",
            "Epoch 91/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1844 - accuracy: 0.9382 - val_loss: 0.0354 - val_accuracy: 0.9925\n",
            "Epoch 92/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.0350 - val_accuracy: 0.9925\n",
            "Epoch 93/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9476 - val_loss: 0.0365 - val_accuracy: 0.9944\n",
            "Epoch 94/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9532 - val_loss: 0.0343 - val_accuracy: 0.9944\n",
            "Epoch 95/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9570 - val_loss: 0.0334 - val_accuracy: 0.9925\n",
            "Epoch 96/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9457 - val_loss: 0.0369 - val_accuracy: 0.9925\n",
            "Epoch 97/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9476 - val_loss: 0.0382 - val_accuracy: 0.9944\n",
            "Epoch 98/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9526 - val_loss: 0.0372 - val_accuracy: 0.9925\n",
            "Epoch 99/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9495 - val_loss: 0.0351 - val_accuracy: 0.9925\n",
            "Epoch 100/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1607 - accuracy: 0.9513 - val_loss: 0.0330 - val_accuracy: 0.9925\n",
            "Epoch 101/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9488 - val_loss: 0.0330 - val_accuracy: 0.9925\n",
            "Epoch 102/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9513 - val_loss: 0.0328 - val_accuracy: 0.9925\n",
            "Epoch 103/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9513 - val_loss: 0.0358 - val_accuracy: 0.9925\n",
            "Epoch 104/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9420 - val_loss: 0.0359 - val_accuracy: 0.9925\n",
            "Epoch 105/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9551 - val_loss: 0.0341 - val_accuracy: 0.9944\n",
            "Epoch 106/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9507 - val_loss: 0.0323 - val_accuracy: 0.9925\n",
            "Epoch 107/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9501 - val_loss: 0.0315 - val_accuracy: 0.9944\n",
            "Epoch 108/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9588 - val_loss: 0.0342 - val_accuracy: 0.9925\n",
            "Epoch 109/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9601 - val_loss: 0.0318 - val_accuracy: 0.9925\n",
            "Epoch 110/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9501 - val_loss: 0.0282 - val_accuracy: 0.9944\n",
            "Epoch 111/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9551 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
            "Epoch 112/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9613 - val_loss: 0.0298 - val_accuracy: 0.9944\n",
            "Epoch 113/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9538 - val_loss: 0.0313 - val_accuracy: 0.9944\n",
            "Epoch 114/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1582 - accuracy: 0.9476 - val_loss: 0.0336 - val_accuracy: 0.9944\n",
            "Epoch 115/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9545 - val_loss: 0.0346 - val_accuracy: 0.9925\n",
            "Epoch 116/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9563 - val_loss: 0.0314 - val_accuracy: 0.9944\n",
            "Epoch 117/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9501 - val_loss: 0.0332 - val_accuracy: 0.9944\n",
            "Epoch 118/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9551 - val_loss: 0.0336 - val_accuracy: 0.9944\n",
            "Epoch 119/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9557 - val_loss: 0.0316 - val_accuracy: 0.9944\n",
            "Epoch 120/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9513 - val_loss: 0.0322 - val_accuracy: 0.9925\n",
            "Epoch 121/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9644 - val_loss: 0.0325 - val_accuracy: 0.9925\n",
            "Epoch 122/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9520 - val_loss: 0.0290 - val_accuracy: 0.9944\n",
            "Epoch 123/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9526 - val_loss: 0.0293 - val_accuracy: 0.9944\n",
            "Epoch 124/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9557 - val_loss: 0.0308 - val_accuracy: 0.9925\n",
            "Epoch 125/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9563 - val_loss: 0.0295 - val_accuracy: 0.9944\n",
            "Epoch 126/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9563 - val_loss: 0.0302 - val_accuracy: 0.9925\n",
            "Epoch 127/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9551 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
            "Epoch 128/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9563 - val_loss: 0.0297 - val_accuracy: 0.9944\n",
            "Epoch 129/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9644 - val_loss: 0.0264 - val_accuracy: 0.9944\n",
            "Epoch 130/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9563 - val_loss: 0.0249 - val_accuracy: 0.9944\n",
            "Epoch 131/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9420 - val_loss: 0.0279 - val_accuracy: 0.9944\n",
            "Epoch 132/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9507 - val_loss: 0.0287 - val_accuracy: 0.9944\n",
            "Epoch 133/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9607 - val_loss: 0.0296 - val_accuracy: 0.9944\n",
            "Epoch 134/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9576 - val_loss: 0.0317 - val_accuracy: 0.9944\n",
            "Epoch 135/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9644 - val_loss: 0.0279 - val_accuracy: 0.9944\n",
            "Epoch 136/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9601 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 137/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9595 - val_loss: 0.0284 - val_accuracy: 0.9944\n",
            "Epoch 138/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9532 - val_loss: 0.0304 - val_accuracy: 0.9944\n",
            "Epoch 139/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9632 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
            "Epoch 140/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9601 - val_loss: 0.0281 - val_accuracy: 0.9944\n",
            "Epoch 141/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9582 - val_loss: 0.0259 - val_accuracy: 0.9944\n",
            "Epoch 142/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9563 - val_loss: 0.0258 - val_accuracy: 0.9944\n",
            "Epoch 143/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9588 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
            "Epoch 144/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9607 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
            "Epoch 145/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9588 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
            "Epoch 146/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9607 - val_loss: 0.0256 - val_accuracy: 0.9944\n",
            "Epoch 147/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9626 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 148/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9545 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 149/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9532 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 150/1000\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9532 - val_loss: 0.0257 - val_accuracy: 0.9944\n",
            "Epoch 150: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1dcddb3a9b0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[TB_callback_sign, Earlystopping_callback_sign]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9944\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_save_path_sign, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(model_save_path_sign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "[0.98479456 0.01384558 0.00135998]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 873us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       174\n",
            "           1       1.00      1.00      1.00       198\n",
            "           2       1.00      0.98      0.99       163\n",
            "\n",
            "    accuracy                           0.99       535\n",
            "   macro avg       0.99      0.99      0.99       535\n",
            "weighted avg       0.99      0.99      0.99       535\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Kibbou\\AppData\\Local\\Temp\\tmpbywv3gx6\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Kibbou\\AppData\\Local\\Temp\\tmpbywv3gx6\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6528"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ()\n",
        "tflite_save_path_sign = 'Model/Sign_classifier_MetaData.tflite'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path_sign, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path_sign)\n",
        "interpreter.allocate_tensors()\n",
        "# \n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# \n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.98479444 0.01384559 0.00135998]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7a3233f10c65cea83d95747b19164ab9f17459359e8424dc1a176cea08d7ac23"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
